{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect polarity in Google app reviews with TensorFlow\n",
    "This work is part of a collection of practice sets called [NLP Starter](https://github.com/jamiemorales/project-nlp-starter).\n",
    "It aims to help someone get started fast and gain a high-level understanding of the fundamental steps in the NLP lifecycle early on.\n",
    "After completion, someone will have built intuition over the NLP lifecycle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Understand the problem\n",
    "What we're trying to do here is to classify whether a Google app review is positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Set-up and understand data\n",
    "In this step, we layout the tools we will need to solve the problem identified in the previous step. We want to inspect our data sources and explore the data itself to gain an understanding of the data for preprocessing and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Set-up libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>I like eat delicious food. That's I'm cooking ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>This help eating healthy exercise regular basis</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.288462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Works great especially going grocery store</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Best idea us</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     App                                  Translated_Review  \\\n",
       "0  10 Best Foods for You  I like eat delicious food. That's I'm cooking ...   \n",
       "1  10 Best Foods for You    This help eating healthy exercise regular basis   \n",
       "2  10 Best Foods for You                                                NaN   \n",
       "3  10 Best Foods for You         Works great especially going grocery store   \n",
       "4  10 Best Foods for You                                       Best idea us   \n",
       "\n",
       "  Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \n",
       "0  Positive                1.00                0.533333  \n",
       "1  Positive                0.25                0.288462  \n",
       "2       NaN                 NaN                     NaN  \n",
       "3  Positive                0.40                0.875000  \n",
       "4  Positive                1.00                0.300000  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../00-Datasets/google-play-store-app-reviews/googleplaystore_user_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64295 entries, 0 to 64294\n",
      "Data columns (total 5 columns):\n",
      "App                       64295 non-null object\n",
      "Translated_Review         37427 non-null object\n",
      "Sentiment                 37432 non-null object\n",
      "Sentiment_Polarity        37432 non-null float64\n",
      "Sentiment_Subjectivity    37432 non-null float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Look at some details\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "App                           0\n",
       "Translated_Review         26868\n",
       "Sentiment                 26863\n",
       "Sentiment_Polarity        26863\n",
       "Sentiment_Subjectivity    26863\n",
       "dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   App Translated_Review Sentiment  Sentiment_Polarity  Sentiment_Subjectivity\n",
       "0  NaN               NaN       NaN                 NaN                     NaN\n",
       "1  NaN               NaN       NaN                 NaN                     NaN\n",
       "2  NaN               NaN       NaN                 NaN                     NaN\n",
       "3  NaN               NaN       NaN                 NaN                     NaN\n",
       "4  NaN               NaN       NaN                 NaN                     NaN\n",
       "5  NaN               NaN       NaN                 NaN                     NaN\n",
       "6  NaN               NaN       NaN                 NaN                     NaN\n",
       "7  NaN               NaN       NaN                 NaN                     NaN\n",
       "8  NaN               NaN       NaN                 NaN                     NaN\n",
       "9  NaN               NaN       NaN                 NaN                     NaN"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at some missing records\n",
    "df[df.isna()].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    23998\n",
       "Negative     8271\n",
       "Neutral      5163\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at breakdown of label\n",
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare data and understand some more\n",
    "In this step, we perform the necessary transformations on the data so that the neural network would be able to understand it. Real-world datasets are complex and messy. For our purposes, most of the datasets we work on in this series require minimal preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we have missing values. It turns out most of these records have NaN across the board. Let's remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App                       0\n",
      "Translated_Review         0\n",
      "Sentiment                 0\n",
      "Sentiment_Polarity        0\n",
      "Sentiment_Subjectivity    0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 37427 entries, 0 to 64230\n",
      "Data columns (total 5 columns):\n",
      "App                       37427 non-null object\n",
      "Translated_Review         37427 non-null object\n",
      "Sentiment                 37427 non-null object\n",
      "Sentiment_Polarity        37427 non-null float64\n",
      "Sentiment_Subjectivity    37427 non-null float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 1.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Remove missing records\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "print(df.isna().sum())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32269 entries, 0 to 64230\n",
      "Data columns (total 5 columns):\n",
      "App                       32269 non-null object\n",
      "Translated_Review         32269 non-null object\n",
      "Sentiment                 32269 non-null object\n",
      "Sentiment_Polarity        32269 non-null float64\n",
      "Sentiment_Subjectivity    32269 non-null float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 1.5+ MB\n",
      "None\n",
      "Positive    23998\n",
      "Negative     8271\n",
      "Name: Sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Remove netural sentiments\n",
    "df.drop(df[df['Sentiment']=='Neutral'].index, inplace=True)\n",
    "\n",
    "print(df.info())\n",
    "print(df['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25815,)\n",
      "(25815,)\n",
      "(6454,)\n",
      "(6454,)\n"
     ]
    }
   ],
   "source": [
    "# Split data into 80% train 20% validation\n",
    "sentences = df['Translated_Review']\n",
    "labels = np.where(df['Sentiment'] == 'Positive', 1, 0)\n",
    "\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(sentences, labels, test_size=0.2, random_state=0)\n",
    "\n",
    "print(train_sentences.shape)\n",
    "print(train_labels.shape)\n",
    "print(val_sentences.shape)\n",
    "print(val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and pad\n",
    "vocab_size = 10000\n",
    "oov_token = '<00V>'\n",
    "max_length = 100\n",
    "padding_type = 'post'\n",
    "trunc_type = 'post'\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "val_sequences = tokenizer.texts_to_sequences(val_sentences)\n",
    "val_padded = pad_sequences(val_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build, train, and evaluate neural network\n",
    "First, we design the neural network, e.g., sequence of layers and activation functions. \n",
    "\n",
    "Second, we train the neural network, we iteratively make a guess, calculate how accurate that guess is, and enhance our guess. The first guess is initialised with random values. The goodness or badness of the guess is measured with the loss function. The next guess is generated and enhanced by the optimizer function.\n",
    "\n",
    "Lastly, we apply use the neural network on previously unseen data and evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25815 samples\n",
      "Epoch 1/5\n",
      "25815/25815 - 2s - loss: 0.5791 - accuracy: 0.7388\n",
      "Epoch 2/5\n",
      "25815/25815 - 1s - loss: 0.5065 - accuracy: 0.7522\n",
      "Epoch 3/5\n",
      "25815/25815 - 1s - loss: 0.3447 - accuracy: 0.8457\n",
      "Epoch 4/5\n",
      "25815/25815 - 1s - loss: 0.2218 - accuracy: 0.9215\n",
      "Epoch 5/5\n",
      "25815/25815 - 1s - loss: 0.1615 - accuracy: 0.9468\n"
     ]
    }
   ],
   "source": [
    "# Build and train neural network\n",
    "embedding_dim = 16\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "history = model.fit(train_padded, train_labels, batch_size=batch_size, epochs=num_epochs, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6454/6454 [==============================] - 0s 39us/sample - loss: 0.1905 - accuracy: 0.9258\n",
      "Val loss: 0.19054529411636864, Val accuracy: 92.57824420928955 \n",
      "\n",
      "\"bombarded with ads makes the app very slow i wish there were less ads\"\n",
      "--> Disliked app.\n",
      "\"super fun and addictive game get it if you like farming games\"\n",
      "--> Liked app.\n",
      "\"very useful app on the go dont need to bring laptop around\"\n",
      "--> Liked app.\n"
     ]
    }
   ],
   "source": [
    "# Apply neural network\n",
    "val_loss, val_accuracy = model.evaluate(val_padded, val_labels)\n",
    "print('Val loss: {}, Val accuracy: {}'.format(val_loss, val_accuracy*100), '\\n')\n",
    "\n",
    "quick_test_sentence = [\n",
    "    'bombarded with ads makes the app very slow i wish there were less ads',\n",
    "    'super fun and addictive game get it if you like farming games',\n",
    "    'very useful app on the go dont need to bring laptop around'\n",
    "]\n",
    "\n",
    "quick_test_sequences = tokenizer.texts_to_sequences(quick_test_sentence)\n",
    "quick_test_padded = pad_sequences(quick_test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "quick_test_sentiments = model.predict(quick_test_padded)\n",
    "\n",
    "\n",
    "for i in range(len(quick_test_sentiments)):\n",
    "    print('\"' + quick_test_sentence[i] + '\"')\n",
    "    if quick_test_sentiments[i] > .75:\n",
    "        print('--> Liked app.')\n",
    "    else:\n",
    "        print('--> Disliked app.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More\n",
    "\n",
    "If you found this work interesting, you might like:\n",
    "\n",
    "* Machine Learning Starter\n",
    "\n",
    "* Deep Learning Starter\n",
    "\n",
    "* Natural Language Processing Starter\n",
    "\n",
    "You can find more at [github.com/jamiemorales](https://github.com/jamiemorales).\n",
    "\n",
    "Datasets are not mine. List of sources: [datasets and sources]()\n",
    "\n",
    "For sharing this work, here's how / the license: https://creativecommons.org/licenses/by-sa/4.0/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
